{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7eeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79dc4fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test_id = df_test[\"PassengerId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5834dc",
   "metadata": {},
   "source": [
    "# Convert Unique Non-Numerical Entries (to Numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "facc95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Replaces identified values, in the provided dataframe, with given replacement values\n",
    "dataframe : pandas.Dataframe\n",
    "vals_to_replace : list\n",
    "replacements : list\n",
    "\"\"\"\n",
    "def replace_vals(dataframe, vals_to_replace, replacements):\n",
    "    dataframe = dataframe.replace(to_replace = vals_to_replace, value = replacements)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee38783",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Name\"], axis=1)\n",
    "df_test = df_test.drop([\"Name\"], axis=1)\n",
    "\n",
    "df = replace_vals(df, [True, False], [1.0, 0.0])\n",
    "df_test = replace_vals(df_test, [True, False], [1.0, 0.0])\n",
    "\n",
    "homes = [\"Europa\", \"Earth\", \"Mars\"]\n",
    "destinations = [\"TRAPPIST-1e\", \"PSO J318.5-22\", \"55 Cancri e\"]\n",
    "\n",
    "df = replace_vals(df, homes, [0.0, 1.0, 2.0])\n",
    "df = replace_vals(df, destinations, [0.0, 1.0, 2.0])\n",
    "\n",
    "df_test = replace_vals(df_test, homes, [0.0, 1.0, 2.0])\n",
    "df_test = replace_vals(df_test, destinations, [0.0, 1.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4731c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Group','People']] = df['PassengerId'].str.split('_',expand=True)\n",
    "df = df.drop(['PassengerId'], axis=1)\n",
    "df[['Deck','Num', 'Side']] = df['Cabin'].str.split('/',expand=True)\n",
    "df = df.drop(['Cabin'], axis=1)\n",
    "\n",
    "df_test[['Group','People']] = df_test['PassengerId'].str.split('_',expand=True)\n",
    "df_test = df_test.drop(['PassengerId'], axis=1)\n",
    "df_test[['Deck','Num', 'Side']] = df_test['Cabin'].str.split('/',expand=True)\n",
    "df_test = df_test.drop(['Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71df6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "decks = ['B', 'F', 'A', 'G', 'E', 'D', 'C', 'T']\n",
    "sides = ['P', 'S']\n",
    "\n",
    "df = replace_vals(df, decks, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0])\n",
    "df_test = replace_vals(df_test, decks, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0])\n",
    "\n",
    "df = replace_vals(df, sides, [1.0, 2.0])\n",
    "df_test = replace_vals(df_test, sides, [1.0, 2.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e3b5a",
   "metadata": {},
   "source": [
    "# Filling in Missing Data (to Avoid Information Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb52d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "\n",
    "\"\"\"\n",
    "Helper functions to pseudo-randomly fill missing values for continuous data\n",
    "\"\"\"\n",
    "codex = {}\n",
    "for i in headers:\n",
    "    vals = []\n",
    "    vals.append(int(df[i].mean()))\n",
    "    vals.append(df[i].median())\n",
    "    vals.append(int(df[i].max()))\n",
    "    codex[i] = vals\n",
    "    \n",
    "def crude_random(target, num):\n",
    "    if num == 0.0:\n",
    "        return codex[target][0]\n",
    "    elif num == 1.0:\n",
    "        return codex[target][1]\n",
    "    else:\n",
    "        return random.choice(range(0,codex[target][2]))\n",
    "    \n",
    "codex_test = {}\n",
    "for i in headers:\n",
    "    vals = []\n",
    "    vals.append(int(df_test[i].mean()))\n",
    "    vals.append(df_test[i].median())\n",
    "    vals.append(int(df_test[i].max()))\n",
    "    codex_test[i] = vals\n",
    "    \n",
    "def crude_random_test(target, num):\n",
    "    if num == 0.0:\n",
    "        return codex_test[target][0]\n",
    "    elif num == 1.0:\n",
    "        return codex_test[target][1]\n",
    "    else:\n",
    "        return random.choice(range(0,codex_test[target][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa09d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_headers = df[headers]\n",
    "df = df.drop(headers, axis=1)\n",
    "\n",
    "for i in headers:\n",
    "    df_temp = df_headers[i].replace(to_replace=np.nan, value=crude_random(i, random.choice([0.0, 1.0, 2.0])))\n",
    "    df = pd.concat([df, df_temp], axis=1)\n",
    "    \n",
    "df_test_headers = df_test[headers]\n",
    "df_test = df_test.drop(headers, axis=1)\n",
    "\n",
    "for i in headers:\n",
    "    df_temp = df_test_headers[i].replace(to_replace=np.nan, value=crude_random_test(i, random.choice([0.0, 1.0, 2.0])))\n",
    "    df_test = pd.concat([df_test, df_temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4a64d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Group'] = df['Group'].astype(float)\n",
    "df['Num'] = df['Num'].astype(float)\n",
    "df['People'] = df['People'].astype(float)\n",
    "\n",
    "df_test['Group'] = df_test['Group'].astype(float)\n",
    "df_test['Num'] = df_test['Num'].astype(float)\n",
    "df_test['People'] = df_test['People'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "303d1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fills missing non-continuous data points under specified columns in the given dataframe \n",
    "dataframe : pandas.Dataframe\n",
    "column_names : list\n",
    "replacements : list\n",
    "\"\"\"\n",
    "def fill_nans(dataframe, column_names, replacements):\n",
    "    temp = dataframe[column_names]\n",
    "    dataframe = dataframe.drop(column_names, axis=1)\n",
    "    temp = temp.replace(to_replace = np.nan, value=random.choice(replacements))\n",
    "    dataframe = pd.concat([dataframe, temp], axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20a3d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_values = [\"CryoSleep\", \"VIP\"]\n",
    "three_values = [\"HomePlanet\", \"Destination\"]\n",
    "no_cabins = [\"Deck\", \"Num\", \"Side\"]\n",
    "\n",
    "df = fill_nans(df, two_values, [0.0, 1.0])\n",
    "df = fill_nans(df, three_values, [0.0, 1.0, 2.0])\n",
    "df = fill_nans(df, no_cabins, [0.0])\n",
    "\n",
    "df_test = fill_nans(df_test, two_values, [0.0, 1.0])\n",
    "df_test = fill_nans(df_test, three_values, [0.0, 1.0, 2.0])\n",
    "df_test = fill_nans(df_test, no_cabins, [0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f2cde",
   "metadata": {},
   "source": [
    "# Check All Information Preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25052f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transported</th>\n",
       "      <th>Group</th>\n",
       "      <th>People</th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>VIP</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Num</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8693.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.503624</td>\n",
       "      <td>4633.389624</td>\n",
       "      <td>1.517773</td>\n",
       "      <td>28.810882</td>\n",
       "      <td>220.009318</td>\n",
       "      <td>938.868975</td>\n",
       "      <td>407.242149</td>\n",
       "      <td>304.588865</td>\n",
       "      <td>622.033590</td>\n",
       "      <td>0.349362</td>\n",
       "      <td>0.022892</td>\n",
       "      <td>0.934085</td>\n",
       "      <td>0.505694</td>\n",
       "      <td>3.438169</td>\n",
       "      <td>586.624065</td>\n",
       "      <td>1.470378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500016</td>\n",
       "      <td>2671.028856</td>\n",
       "      <td>1.054241</td>\n",
       "      <td>14.339536</td>\n",
       "      <td>660.519050</td>\n",
       "      <td>3645.965586</td>\n",
       "      <td>1606.720763</td>\n",
       "      <td>1125.562559</td>\n",
       "      <td>2415.778883</td>\n",
       "      <td>0.476796</td>\n",
       "      <td>0.149568</td>\n",
       "      <td>0.682874</td>\n",
       "      <td>0.814966</td>\n",
       "      <td>1.809941</td>\n",
       "      <td>513.880084</td>\n",
       "      <td>0.543084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2319.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4630.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>407.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6883.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>983.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9280.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>14327.000000</td>\n",
       "      <td>29813.000000</td>\n",
       "      <td>23492.000000</td>\n",
       "      <td>22408.000000</td>\n",
       "      <td>24133.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1894.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Transported        Group       People          Age   RoomService  \\\n",
       "count  8693.000000  8693.000000  8693.000000  8693.000000   8693.000000   \n",
       "mean      0.503624  4633.389624     1.517773    28.810882    220.009318   \n",
       "std       0.500016  2671.028856     1.054241    14.339536    660.519050   \n",
       "min       0.000000     1.000000     1.000000     0.000000      0.000000   \n",
       "25%       0.000000  2319.000000     1.000000    20.000000      0.000000   \n",
       "50%       1.000000  4630.000000     1.000000    27.000000      0.000000   \n",
       "75%       1.000000  6883.000000     2.000000    37.000000     41.000000   \n",
       "max       1.000000  9280.000000     8.000000    79.000000  14327.000000   \n",
       "\n",
       "          FoodCourt  ShoppingMall           Spa        VRDeck    CryoSleep  \\\n",
       "count   8693.000000   8693.000000   8693.000000   8693.000000  8693.000000   \n",
       "mean     938.868975    407.242149    304.588865    622.033590     0.349362   \n",
       "std     3645.965586   1606.720763   1125.562559   2415.778883     0.476796   \n",
       "min        0.000000      0.000000      0.000000      0.000000     0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000     0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000     0.000000   \n",
       "75%      118.000000     45.000000     53.000000     71.000000     1.000000   \n",
       "max    29813.000000  23492.000000  22408.000000  24133.000000     1.000000   \n",
       "\n",
       "               VIP   HomePlanet  Destination         Deck          Num  \\\n",
       "count  8693.000000  8693.000000  8693.000000  8693.000000  8693.000000   \n",
       "mean      0.022892     0.934085     0.505694     3.438169   586.624065   \n",
       "std       0.149568     0.682874     0.814966     1.809941   513.880084   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     2.000000   152.000000   \n",
       "50%       0.000000     1.000000     0.000000     4.000000   407.000000   \n",
       "75%       0.000000     1.000000     1.000000     4.000000   983.000000   \n",
       "max       1.000000     2.000000     2.000000     8.000000  1894.000000   \n",
       "\n",
       "              Side  \n",
       "count  8693.000000  \n",
       "mean      1.470378  \n",
       "std       0.543084  \n",
       "min       0.000000  \n",
       "25%       1.000000  \n",
       "50%       1.000000  \n",
       "75%       2.000000  \n",
       "max       2.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f50309f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>People</th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>VIP</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Num</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>4277.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4639.296469</td>\n",
       "      <td>1.498714</td>\n",
       "      <td>29.431377</td>\n",
       "      <td>215.062427</td>\n",
       "      <td>439.472294</td>\n",
       "      <td>177.288754</td>\n",
       "      <td>445.990881</td>\n",
       "      <td>594.447042</td>\n",
       "      <td>0.382745</td>\n",
       "      <td>0.039046</td>\n",
       "      <td>0.961655</td>\n",
       "      <td>0.483984</td>\n",
       "      <td>3.426233</td>\n",
       "      <td>595.912322</td>\n",
       "      <td>1.465981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2716.197368</td>\n",
       "      <td>1.018221</td>\n",
       "      <td>14.975870</td>\n",
       "      <td>601.914503</td>\n",
       "      <td>1508.609203</td>\n",
       "      <td>554.357253</td>\n",
       "      <td>1436.519802</td>\n",
       "      <td>2398.014471</td>\n",
       "      <td>0.486114</td>\n",
       "      <td>0.193727</td>\n",
       "      <td>0.685223</td>\n",
       "      <td>0.801973</td>\n",
       "      <td>1.811638</td>\n",
       "      <td>517.198106</td>\n",
       "      <td>0.543759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2249.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4639.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7030.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9277.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>11567.000000</td>\n",
       "      <td>25273.000000</td>\n",
       "      <td>8292.000000</td>\n",
       "      <td>19844.000000</td>\n",
       "      <td>22272.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1890.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Group       People          Age   RoomService     FoodCourt  \\\n",
       "count  4277.000000  4277.000000  4277.000000   4277.000000   4277.000000   \n",
       "mean   4639.296469     1.498714    29.431377    215.062427    439.472294   \n",
       "std    2716.197368     1.018221    14.975870    601.914503   1508.609203   \n",
       "min      13.000000     1.000000     0.000000      0.000000      0.000000   \n",
       "25%    2249.000000     1.000000    20.000000      0.000000      0.000000   \n",
       "50%    4639.000000     1.000000    27.000000      0.000000      0.000000   \n",
       "75%    7030.000000     2.000000    38.000000     48.000000    143.000000   \n",
       "max    9277.000000     8.000000    79.000000  11567.000000  25273.000000   \n",
       "\n",
       "       ShoppingMall           Spa        VRDeck    CryoSleep          VIP  \\\n",
       "count   4277.000000   4277.000000   4277.000000  4277.000000  4277.000000   \n",
       "mean     177.288754    445.990881    594.447042     0.382745     0.039046   \n",
       "std      554.357253   1436.519802   2398.014471     0.486114     0.193727   \n",
       "min        0.000000      0.000000      0.000000     0.000000     0.000000   \n",
       "25%        0.000000      0.000000      0.000000     0.000000     0.000000   \n",
       "50%        0.000000      0.000000      0.000000     0.000000     0.000000   \n",
       "75%       51.000000     83.000000     53.000000     1.000000     0.000000   \n",
       "max     8292.000000  19844.000000  22272.000000     1.000000     1.000000   \n",
       "\n",
       "        HomePlanet  Destination         Deck          Num         Side  \n",
       "count  4277.000000  4277.000000  4277.000000  4277.000000  4277.000000  \n",
       "mean      0.961655     0.483984     3.426233   595.912322     1.465981  \n",
       "std       0.685223     0.801973     1.811638   517.198106     0.543759  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     2.000000   162.000000     1.000000  \n",
       "50%       1.000000     0.000000     4.000000   416.000000     1.000000  \n",
       "75%       1.000000     1.000000     4.000000  1012.000000     2.000000  \n",
       "max       2.000000     2.000000     8.000000  1890.000000     2.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50297720",
   "metadata": {},
   "source": [
    "# Prepare Data to Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06052a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_target = df[\"Transported\"]\n",
    "train_features = df.drop([\"Transported\", \"Group\"], axis=1)\n",
    "test_features = df_test.drop([\"Group\"],axis=1)\n",
    "\n",
    "st_scaler = StandardScaler()\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_features, train_target, test_size=0.05)\n",
    "x_train = st_scaler.fit_transform(x_train) \n",
    "x_test = st_scaler.transform(x_test)\n",
    "\n",
    "st_scaler2 = StandardScaler()\n",
    "fit_tr = st_scaler2.fit_transform(train_features)\n",
    "to_test = st_scaler2.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfab0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\"\"\"\n",
    "RandomizedSearchCV used to identify the set of parameters, for a given model, that produces the highest f1 score\n",
    "model : object\n",
    "distributions : dictionary of lists\n",
    "\"\"\"\n",
    "def best_params(model, distributions):\n",
    "    cvFold = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    clf = RandomizedSearchCV(scoring='f1_micro', estimator=model, cv=cvFold, param_distributions=distributions)\n",
    "    search = clf.fit(x_train, y_train)\n",
    "    result = search.best_params_\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "GridSearchCV used to identify the set of parameters, for a given model, that produces the highest f1 score\n",
    "model : object\n",
    "grid : dictionary of lists\n",
    "\"\"\"\n",
    "def best_params_grid(model, grid):\n",
    "    cvFold = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    clf = GridSearchCV(scoring='f1_micro', estimator=model, cv=cvFold, param_grid=grid)\n",
    "    search = clf.fit(x_train, y_train)\n",
    "    result = search.best_params_\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "Provided model is used to predict unlabelled data. Writes the results to a .csv file of given name\n",
    "model : object\n",
    "name : string\n",
    "\"\"\"\n",
    "def create_file(model, name):\n",
    "    predictions = pd.DataFrame(model.predict(to_test))\n",
    "    predictions = predictions.replace(to_replace=[1.0, 0.0],\n",
    "           value=[True, False])\n",
    "    predictions = predictions.rename({0: \"Transported\"}, axis=1)\n",
    "    pd.concat([df_test_id, predictions],axis = 1).to_csv(name+\".csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03713a0b",
   "metadata": {},
   "source": [
    "# Training Models with Optimized Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36469e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 106, 'max_depth': 4}\n",
      "0.8481415929203541\n",
      "0.8244897959183672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "distributions = {'n_estimators': range(1, 200),\n",
    "                'max_depth': range(1, 20)}\n",
    "params = best_params(GradientBoostingClassifier(), distributions)\n",
    "gbc = GradientBoostingClassifier(n_estimators = params['n_estimators'], max_depth = params['max_depth'])\n",
    "gbc.fit(x_train, y_train)\n",
    "\n",
    "print(f1_score(y_train, gbc.predict(x_train)))\n",
    "print(f1_score(y_test, gbc.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1134290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 37, 'max_depth': 18}\n",
      "0.9282933567750848\n",
      "0.7747747747747746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "distributions = {'n_estimators': range(1, 100),\n",
    "                'max_depth': range(1, 20)}\n",
    "params = best_params(ExtraTreesClassifier(), distributions)\n",
    "et = ExtraTreesClassifier(n_estimators = params['n_estimators'], max_depth = params['max_depth'])\n",
    "et.fit(x_train, y_train)\n",
    "\n",
    "print(f1_score(y_train, et.predict(x_train)))\n",
    "print(f1_score(y_test, et.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69038b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 69, 'max_depth': 12}\n",
      "0.904710535778497\n",
      "0.803347280334728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "distributions = {'n_estimators': range(1, 100),\n",
    "                'max_depth': range(1, 20)}\n",
    "params = best_params(RandomForestClassifier(), distributions)\n",
    "rf = RandomForestClassifier(n_estimators = params['n_estimators'], max_depth = params['max_depth'])\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "print(f1_score(y_train, rf.predict(x_train)))\n",
    "print(f1_score(y_test, rf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e43d696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 6}\n",
      "0.8054288321167884\n",
      "0.7857142857142858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "distributions = {'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': range(1, 20)}\n",
    "params = best_params_grid(DecisionTreeClassifier(), distributions)\n",
    "dtc = DecisionTreeClassifier(criterion = params['criterion'], max_depth = params['max_depth'])\n",
    "dtc.fit(x_train, y_train)\n",
    "\n",
    "print(f1_score(y_train, dtc.predict(x_train)))\n",
    "print(f1_score(y_test, dtc.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6baf5342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'max_iter': 300}\n",
      "0.8453807967066231\n",
      "0.8118393234672303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wintk\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "distributions = {'activation': ['logistic', 'tanh', 'relu'],\n",
    "                'max_iter': [200, 300, 400, 500]}\n",
    "params = best_params_grid(MLPClassifier(early_stopping=True), distributions)\n",
    "mlp = MLPClassifier(activation = params['activation'], max_iter = params['max_iter'] )\n",
    "mlp.fit(x_train, y_train)\n",
    "\n",
    "print(f1_score(y_train, mlp.predict(x_train)))\n",
    "print(f1_score(y_test, mlp.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c7985c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator': RandomForestClassifier(max_depth=12, n_estimators=69)}\n",
      "0.9998792124652737\n",
      "0.8193832599118942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "distributions = {'base_estimator': [et, rf, dtc]}\n",
    "params = best_params_grid(AdaBoostClassifier(), distributions)\n",
    "ada = AdaBoostClassifier(base_estimator = params['base_estimator'])\n",
    "ada.fit(x_train, y_train)\n",
    "\n",
    "print(f1_score(y_train, ada.predict(x_train)))\n",
    "print(f1_score(y_test, ada.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc9d211c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator': GradientBoostingClassifier(max_depth=4, n_estimators=106)}\n",
      "0.842067565954399\n",
      "0.8329896907216495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "distributions = {'base_estimator': [gbc, et, rf, dtc]}\n",
    "params = best_params_grid(BaggingClassifier(), distributions)\n",
    "bag = BaggingClassifier(base_estimator = params['base_estimator'])\n",
    "bag.fit(x_train, y_train)\n",
    "\n",
    "print(f1_score(y_train, bag.predict(x_train)))\n",
    "print(f1_score(y_test, bag.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8809a6",
   "metadata": {},
   "source": [
    "# Picking Models with Higher Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6642a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models with f1 score > 0.8\n",
    "create_file(gbc, \"gbc_106_4\")\n",
    "create_file(rf, \"rf_69_12\")\n",
    "create_file(mlp, \"mlp_relu300\")\n",
    "create_file(ada, \"ada_rf_69_12\")\n",
    "create_file(bag, \"bag_gbc_106_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d6d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
